name: Daily AI News Scraper

on:
  schedule:
    # Run every day at 00:00 UTC (5:30 AM IST)
    - cron: '0 0 * * *'
  workflow_dispatch: # Allow manual trigger

permissions:
  contents: write

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          pip install requests==2.31.0 beautifulsoup4==4.12.3 lxml==5.1.0
          
      - name: Run scraper
        run: |
          mkdir -p .tmp
          python tools/manager.py
          
      - name: Commit and push if changed
        run: |
          git config --global user.name 'GitHub Actions Bot'
          git config --global user.email 'actions@github.com'
          # Check status before adding
          echo "Current git status:"
          git status
          
          # Add files
          git add articles.json || echo "articles.json not found"
          git add progress.md || echo "progress.md not found"
          
          # Check status after adding
          echo "Status after add:"
          git status
          
          # Commit only if there are changes
          if ! git diff --staged --quiet; then
            git commit -m "Update articles - $(date -u +'%Y-%m-%d %H:%M UTC')"
            # Pull with rebase, favoring the upstream changes (theirs) to resolve conflicts automatically
            git pull --rebase -X theirs origin main
            git push
            echo "::notice::Successfully pushed updates to GitHub"
          else
            echo "::notice::No changes detected. Skipping commit."
          fi
